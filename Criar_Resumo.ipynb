{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Criar_Resumo.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOZuuv/TsZ9mZkyTYXqFIy3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ijusplab/criar-resumo/blob/main/Criar_Resumo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExKamrA-ZWAQ"
      },
      "source": [
        "# **10ª Turma Recursal**\n",
        "## Gerenciamento de Pauta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU-DUwtdlUKU"
      },
      "source": [
        "## **Instruções**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSPZNx8LZfpb"
      },
      "source": [
        "**INSTRUÇÕES**\n",
        "\n",
        "1) Execute a célula `CARREGAR FERRAMENTA`. \n",
        "\n",
        "2) Execute a célula `CARREGAR DADOS DO SHAREPOINT`. \n",
        "\n",
        "3) Assim que o código for inicializado e aparecer o botão de `upload`, carregue o arquivo `csv` do sharepoint. Você verá uma prévia do conteúdo extraído logo abaixo da célula, em forma de tabela.\n",
        "\n",
        "4) Execute a célula `GERAR ARQUIVO JSON`. O arquivo será baixado no seu browser em poucos segundos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ES4_qUwmAVP"
      },
      "source": [
        "## **CARREGAR FERRAMENTA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xlQaZbTITHl",
        "cellView": "code"
      },
      "source": [
        "#@title **CARREGAR FERRAMENTA** { vertical-output: true }\n",
        "MODO_DEPURACAO = False\n",
        "\n",
        "import re, os, json, csv, pprint\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "##\n",
        "## Mensagens\n",
        "##\n",
        "\n",
        "class mensageria:\n",
        "  __END      = '\\33[0m'\n",
        "  __BOLD     = '\\33[1m'\n",
        "  __ITALIC   = '\\33[3m'\n",
        "  __URL      = '\\33[4m'\n",
        "  __BLINK    = '\\33[5m'\n",
        "  __BLINK2   = '\\33[6m'\n",
        "  __SELECTED = '\\33[7m'\n",
        "\n",
        "  __BLACK  = '\\33[30m'\n",
        "  __RED    = '\\33[31m'\n",
        "  __GREEN  = '\\33[32m'\n",
        "  __YELLOW = '\\33[33m'\n",
        "  __BLUE   = '\\33[34m'\n",
        "  __VIOLET = '\\33[35m'\n",
        "  __BEIGE  = '\\33[36m'\n",
        "  __WHITE  = '\\33[37m'\n",
        "\n",
        "  __BLACKBG  = '\\33[40m'\n",
        "  __REDBG    = '\\33[41m'\n",
        "  __GREENBG  = '\\33[42m'\n",
        "  __YELLOWBG = '\\33[43m'\n",
        "  __BLUEBG   = '\\33[44m'\n",
        "  __VIOLETBG = '\\33[45m'\n",
        "  __BEIGEBG  = '\\33[46m'\n",
        "  __WHITEBG  = '\\33[47m'\n",
        "\n",
        "  __GREY    = '\\33[90m'\n",
        "  __RED2    = '\\33[91m'\n",
        "  __GREEN2  = '\\33[92m'\n",
        "  __YELLOW2 = '\\33[93m'\n",
        "  __BLUE2   = '\\33[94m'\n",
        "  __VIOLET2 = '\\33[95m'\n",
        "  __BEIGE2  = '\\33[96m'\n",
        "  __WHITE2  = '\\33[97m'\n",
        "\n",
        "  __GREYBG    = '\\33[100m'\n",
        "  __REDBG2    = '\\33[101m'\n",
        "  __GREENBG2  = '\\33[102m'\n",
        "  __YELLOWBG2 = '\\33[103m'\n",
        "  __BLUEBG2   = '\\33[104m'\n",
        "  __VIOLETBG2 = '\\33[105m'\n",
        "  __BEIGEBG2  = '\\33[106m'\n",
        "  __WHITEBG2  = '\\33[107m'\n",
        "\n",
        "  @classmethod\n",
        "  def sucesso(cls, msg):\n",
        "    print(f'{cls.__BLUE}{cls.__BOLD}{msg}{cls.__END}')\n",
        "\n",
        "  @classmethod\n",
        "  def falha(cls, msg):\n",
        "    print(f'{cls.__REDBG}{cls.__WHITE}{msg}{cls.__END}')\n",
        "\n",
        "  @classmethod\n",
        "  def alerta(cls, msg):\n",
        "    print(f'{cls.__YELLOWBG}{msg}{cls.__END}')\n",
        "\n",
        "  @classmethod\n",
        "  def ok(cls, msg):\n",
        "    print(f'{cls.__GREEN}{cls.__BOLD}{msg}{cls.__END}')\n",
        "\n",
        "  @classmethod\n",
        "  def normal(cls, msg):\n",
        "    print(f'{cls.__BOLD}{msg}{cls.__END}')\n",
        "\n",
        "  @classmethod\n",
        "  def mostrar_objeto(cls, obj):\n",
        "    printer = pprint.PrettyPrinter(indent=4)\n",
        "    printer.pprint(obj)\n",
        "\n",
        "##\n",
        "## Para normalização dos nomes de colunas\n",
        "##\n",
        "class utils:\n",
        "  __acentos = {\n",
        "    'a': re.compile('[áàäãâ]'), \n",
        "    'e': re.compile('[éèëê]'), \n",
        "    'i': re.compile('[íìïî]'),\n",
        "    'o': re.compile('[óòöõô]'),\n",
        "    'u': re.compile('[úùüû]'),\n",
        "    'c': re.compile('[ç]'),\n",
        "    'A': re.compile('[ÁÀÄÃÂ]'), \n",
        "    'E': re.compile('[ÉÈËÊ]'), \n",
        "    'I': re.compile('[ÍÌÏÎ]'),\n",
        "    'O': re.compile('[ÓÒÖÕÔ]'),\n",
        "    'U': re.compile('[ÚÙÜÛ]'),\n",
        "    'C': re.compile('[Ç]')\n",
        "  }\n",
        "  __caracteres_especiais = re.compile('[\\(\\)\\[\\]\\{\\}!@#$%¨&*+=ªº°§]')\n",
        "\n",
        "  @classmethod\n",
        "  def remover_acentuacao(cls, s):\n",
        "    for letra, padrao in cls.__acentos.items():\n",
        "      s = re.sub(padrao, letra, s)\n",
        "    return s\n",
        "\n",
        "  @classmethod\n",
        "  def limpar(cls, s):\n",
        "    s = cls.remover_acentuacao(s).upper().strip()\n",
        "    s = re.sub(cls.__caracteres_especiais, '', s).strip()\n",
        "    s = re.sub(r'\\s{2,}', ' ', s).strip()\n",
        "    return s\n",
        "\n",
        "  @classmethod\n",
        "  def normalizar(cls, s):\n",
        "    s = cls.remover_acentuacao(s).upper().strip()\n",
        "    s = re.sub(r'\\d+_+', '', s)\n",
        "    s = re.sub(r'\\s+', '_', s)\n",
        "    return s\n",
        "\n",
        "##\n",
        "## Extração dos dados do sharepoint\n",
        "##\n",
        "class Sharepoint:\n",
        "  _instance = None\n",
        "\n",
        "  def __init__(self):\n",
        "    self.__resumo = None\n",
        "    self.__votos = None\n",
        "    self.__pastas = None\n",
        "    self.__nome = ''\n",
        "    self._cols = {\n",
        "      \"PROCESSO\": \"PROCESSO\",\n",
        "      \"OBJETO\": \"OBJETO\",\n",
        "      \"ALEGACOES\": \"ALEGACOES\",\n",
        "      \"FUNDAMENTACAO\": \"FUNDAMENTACAO\",\n",
        "      \"DISPOSITIVO\": \"DISPOSITIVO\",\n",
        "      \"OBSERVACOES\": \"OBSERVACOES\",\n",
        "      \"STATUS_JULGAMENTO\": \"STATUS_JULGAMENTO\",\n",
        "      \"SITUACAO_PAUTA\": \"SITUACAO_PAUTA\",\n",
        "      \"TIPO_VOTO\": \"TIPO_VOTO\",\n",
        "      \"{IsFolder}\": \"IS_FOLDER\",\n",
        "      \"{Link}\": \"LINK\",\n",
        "      \"{Name}\": \"NAME\",\n",
        "      \"{Path}\": \"PATH\",\n",
        "      \"{FullPath}\": \"FULL_PATH\"\n",
        "    }\n",
        "\n",
        "  @classmethod\n",
        "  def instance(cls):\n",
        "      if cls._instance is None:\n",
        "          cls._instance = cls()\n",
        "      return cls._instance\n",
        "\n",
        "  def __extrair_cadeira(self, s):\n",
        "    pattern = re.compile('Cadeira\\s(\\d+)')\n",
        "    match = pattern.search(s)\n",
        "    if not match:\n",
        "      return ''\n",
        "    return match.group(1)\n",
        "\n",
        "  def __transformar_nome_coluna(self, s):\n",
        "    if s in self._cols:\n",
        "      return self._cols[s]\n",
        "    return s\n",
        "\n",
        "  def __extrair_valor(self, s):\n",
        "    pattern = re.compile('\\\"Value\\\":\\\"(.+)\\\"')\n",
        "    match = pattern.search(s)\n",
        "    if not match:\n",
        "      return ''\n",
        "    return match.group(1)\n",
        "\n",
        "  def __extrair_numero_processo(self, s):\n",
        "    pattern = re.compile('\\d{7}-\\d{2}\\.\\d{4}\\.\\d\\.\\d{2}\\.\\d{4}')\n",
        "    match = pattern.search(s)\n",
        "    if not match:\n",
        "      return ''\n",
        "    return match.group(0)\n",
        "\n",
        "  # obtem grupo do voto (a partir das duas pastas acima)\n",
        "  # a partir de /pasta1/pasta2/arquivo, retorna pasta1_pasta2 \n",
        "  def __obter_grupo(self, s):\n",
        "    pattern = re.compile('.*\\/([^\\/]+\\/[^\\/]+)\\/')\n",
        "    match = pattern.search(s)\n",
        "    if not match:\n",
        "      return ''\n",
        "    return match.group(1).replace('/', '_')\n",
        "\n",
        "  def __obter_dic_processos(self, df):\n",
        "    dic = {}\n",
        "    for index, row in df.iterrows():\n",
        "      key = re.sub('\\D', '', row['PROCESSO'])\n",
        "      dic[key] = {}\n",
        "      dic[key]['so'] = False\n",
        "      dic[key]['adv'] = ''\n",
        "      dic[key]['sit'] = row['SITUACAO_PAUTA']\n",
        "      dic[key]['concl'] = False\n",
        "      dic[key]['jimp'] = ''\n",
        "    return dic\n",
        "\n",
        "  def __obter_grupos_ordenados(self, df_folders):\n",
        "    list = []\n",
        "    pattern = re.compile('^\\d+$')\n",
        "    for index, row in df_folders.iterrows():\n",
        "      dic = {}\n",
        "      dic['titulo'] = row['GRUPO']\n",
        "      dic['status'] = re.sub('\\D', '', row['STATUS_JULGAMENTO'])\n",
        "      dic['situacao'] = re.sub('\\D', '', row['SITUACAO_PAUTA'])\n",
        "      dic['tipo'] = re.sub('\\D', '', row['TIPO_VOTO'])\n",
        "      dic['observacoes'] = row['OBSERVACOES']\n",
        "      dic['dispositivo'] = row['DISPOSITIVO']\n",
        "      dic['link'] = row['LINK']\n",
        "      lote = len(row['LOTE'].split('\\n'))\n",
        "      dic['lote'] = [] if len(row['LOTE']) == 0 else lote\n",
        "      list.append(dic)\n",
        "    list.sort(key=lambda item: 1000 if not pattern.search(item['tipo']) else int(item['tipo']))\n",
        "    return list\n",
        "\n",
        "  def __obter_list_resumo(self, df_files, sorted_groups):\n",
        "    grouped = df_files.groupby('GRUPO')\n",
        "    resumo = []\n",
        "    counter = 1\n",
        "\n",
        "    for group in sorted_groups:\n",
        "      try:\n",
        "        items = grouped.get_group(group['titulo'])\n",
        "      except KeyError:\n",
        "        continue\n",
        "      if len(items) == 0:\n",
        "        continue\n",
        "\n",
        "      root = {}\n",
        "      titulo = group['titulo']\n",
        "      root['titulo'] = f'{counter}.{titulo}'\n",
        "      root['observacoes'] = group['observacoes']\n",
        "      root['link'] = group['link']\n",
        "      root['tipo'] = 'lote' if len(group['lote']) > 0 else 'normal'\n",
        "      coluna1 = {}\n",
        "      coluna1['numero'] = 1\n",
        "      coluna1['tamanho'] = 47\n",
        "      coluna1['nome'] = 'Alegações Recursais'\n",
        "      coluna2 = {}\n",
        "      coluna2['numero'] = 2\n",
        "      coluna2['tamanho'] = 35\n",
        "      coluna2['nome'] = 'Fundamentação'\n",
        "      coluna3 = {}\n",
        "      coluna3['numero'] = 2\n",
        "      coluna3['tamanho'] = 18\n",
        "      coluna3['nome'] = 'Resultado'\n",
        "      root['colunas'] = [coluna1, coluna2, coluna3]\n",
        "\n",
        "      processos = []\n",
        "      subcounter = 1\n",
        "      for index, row in items.iterrows():\n",
        "        processo = {}\n",
        "        processo['numero'] = re.sub('\\D', '', row['PROCESSO'])\n",
        "        processo['item'] = f'{counter}.{subcounter}'\n",
        "        processo['ordem']: f'{str(counter).zfill(3)}{str(index).zfill(3)}'\n",
        "        coluna1 = {}\n",
        "        coluna1['numero'] = 1\n",
        "        coluna1['tamanho'] = 47\n",
        "        coluna1['conteudo'] = ''\n",
        "        coluna2 = {}\n",
        "        coluna2['numero'] = 2\n",
        "        coluna2['tamanho'] = 35\n",
        "        coluna2['conteudo'] = ''\n",
        "        coluna3 = {}\n",
        "        coluna3['numero'] = 2\n",
        "        coluna3['tamanho'] = 18\n",
        "        coluna3['conteudo'] = row['DISPOSITIVO']\n",
        "        processo['colunas'] = [coluna1, coluna2, coluna3]\n",
        "        processos.append(processo)\n",
        "        subcounter += 1\n",
        "\n",
        "      root['processos'] = processos\n",
        "      resumo.append(root)\n",
        "      counter += 1\n",
        "    \n",
        "    return resumo\n",
        "\n",
        "  def load(self):\n",
        "    # uploaded = files.upload()\n",
        "    # arquivos = list(uploaded.keys())\n",
        "    # print(arquivos)\n",
        "    # if len(arquivos) > 0:\n",
        "    nome = '2021-07-30.csv' #arquivos[0]\n",
        "    # conteudo = uploaded[nome] \n",
        "\n",
        "    if re.match('^.+\\.(csv)$', nome):\n",
        "\n",
        "      # converte csv em dataframe, mantendo somente as\n",
        "      # colunas desejadas\n",
        "      df = pd.read_csv(nome, sep=',', encoding='utf-8')\n",
        "      df = df.fillna('')\n",
        "      df.drop(df.columns.difference(list(self._cols.keys())), 1, inplace=True)\n",
        "      df.columns = map(self.__transformar_nome_coluna, df.columns)\n",
        "\n",
        "      # Compõe o nome do arquivo\n",
        "      cadeira = self.__extrair_cadeira(df.at[0, 'PATH'])\n",
        "      data = nome.replace('.csv', '').split('-')\n",
        "      data.reverse()\n",
        "      data = ''.join(data)\n",
        "      self.__nome = f'{cadeira}{data}'\n",
        "\n",
        "      # Extrai o valor das colunas customizadas do Sharepoint\n",
        "      custom = ['STATUS_JULGAMENTO', 'SITUACAO_PAUTA', 'TIPO_VOTO', 'OBSERVACOES', 'DISPOSITIVO', 'LOTE']\n",
        "      for col_name in custom:\n",
        "        if col_name not in df.columns:\n",
        "          df[col_name] = pd.Series()\n",
        "          df[col_name] = df[col_name].fillna('')\n",
        "        else:\n",
        "          df[col_name] = df[col_name].apply(self.__extrair_valor)\n",
        "\n",
        "      # Separa pastas e arquivos\n",
        "      grouped = df.groupby(df['IS_FOLDER'])\n",
        "      folders = grouped.get_group(True).copy()\n",
        "      files = grouped.get_group(False).copy()\n",
        "\n",
        "      # Identifica as divisões do resumo a partir das pastas\n",
        "      folders['GRUPO'] = folders['FULL_PATH'].apply(lambda x: f'{x}/').apply(self.__obter_grupo)\n",
        "      grupos = self.__obter_grupos_ordenados(folders)\n",
        "\n",
        "      # cria coluna com números de processos\n",
        "      # e identifica se há nomes de arquivos inválidos\n",
        "      files['PROCESSO'] = files['NAME'].apply(self.__extrair_numero_processo)\n",
        "      try:\n",
        "        errors = files.groupby(files['PROCESSO']).get_group('')['NAME'].tolist()\n",
        "      except:\n",
        "        errors = []\n",
        "\n",
        "      if len(errors) > 0:\n",
        "        errors = '\\n'.join(errors)\n",
        "        mensageria.falha(f'\\n>>>> Os seguintes arquivos têm nome irregular:\\n {errors}')\n",
        "        return\n",
        "\n",
        "      # cria coluna com a localização dos processos\n",
        "      # e identifica se há localizações inválidas\n",
        "      files['GRUPO'] = files['PATH'].apply(self.__obter_grupo)\n",
        "\n",
        "      try:\n",
        "        errors = files.groupby(files['GRUPO']).get_group('')['NAME'].tolist()\n",
        "      except:\n",
        "        errors = []\n",
        "\n",
        "      if len(errors) > 0:\n",
        "        errors = '\\n'.join(errors)\n",
        "        mensageria.falha(f'\\n>>>> Os seguintes arquivos têm localização irregular:\\n {errors}')\n",
        "        return\n",
        "\n",
        "      # Converte dados em dicionário\n",
        "      self.__resumo = {}\n",
        "      self.__resumo['processos'] = self.__obter_dic_processos(files)\n",
        "      self.__resumo['resumo'] = self.__obter_list_resumo(files, grupos)\n",
        "      self.__votos = files\n",
        "      self.__pastas = folders\n",
        "\n",
        "      # os.remove(nome)\n",
        "      # else:\n",
        "      #   mensageria.falha(f'\\n>>>> O arquivo {nome} não é um txt')\n",
        "\n",
        "  def has_data_frame(self):\n",
        "    return not self.__votos is None and not self.__pastas is None\n",
        "\n",
        "  def get_name(self):\n",
        "    if not self.has_data_frame():\n",
        "      mensageria.falha('\\n>>>> NÃO HÁ DADOS CARREGADOS')\n",
        "      return\n",
        "    return self.__nome\n",
        "\n",
        "  def get_data_frame(self):\n",
        "    if not self.has_data_frame():\n",
        "      mensageria.falha('\\n>>>> NÃO HÁ DADOS CARREGADOS')\n",
        "      return\n",
        "    return self.__data_frame\n",
        "\n",
        "  def show_votos(self):\n",
        "    if not self.has_data_frame():\n",
        "      mensageria.falha('\\n>>>> NÃO HÁ DADOS CARREGADOS')\n",
        "      return\n",
        "    print()\n",
        "    mensageria.normal('\\n>>>> VOTOS')\n",
        "    display(HTML(self.__votos.head().to_html()))\n",
        "    mensageria.normal('\\n>>>> TIPOS')\n",
        "    for col in self.__votos.columns:\n",
        "      print(f'{col}: {self.__votos[col].dtype}')\n",
        "\n",
        "  def show_pastas(self):\n",
        "    if not self.has_data_frame():\n",
        "      mensageria.falha('\\n>>>> NÃO HÁ DADOS CARREGADOS')\n",
        "      return\n",
        "    print()\n",
        "    mensageria.normal('\\n>>>> PASTAS')\n",
        "    display(HTML(self.__pastas.head().to_html()))\n",
        "    mensageria.normal('\\n>>>> TIPOS')\n",
        "    for col in self.__pastas.columns:\n",
        "      print(f'{col}: {self.__pastas[col].dtype}')\n",
        "\n",
        "  def show_resumo(self):\n",
        "    if not self.has_data_frame():\n",
        "      mensageria.falha('\\n>>>> NÃO HÁ DADOS CARREGADOS')\n",
        "      return\n",
        "    mensageria.normal('\\n>>>> JSON')\n",
        "    print(json.dumps(self.__resumo, indent=2))\n",
        "\n",
        "  def download(self):\n",
        "    if not self.has_data_frame():\n",
        "      mensageria.falha('\\n>>>> NÃO HÁ DADOS CARREGADOS')\n",
        "      return\n",
        "    nome = f'{self.__nome}.json'\n",
        "    if os.path.isfile(nome):\n",
        "      os.remove(nome)\n",
        "    with open(nome, 'w', encoding='utf-8') as file:\n",
        "      file.write(json.dumps(self.__resumo, indent=2))\n",
        "    files.download(nome)\n",
        "\n",
        "print()\n",
        "mensageria.sucesso('\\n>>>> Ferramentas carregadas com sucesso!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNdsNidKZQEP"
      },
      "source": [
        "#@title **CARREGAR DADOS DO SHAREPOINT** { vertical-output: true }\n",
        "\n",
        "##\n",
        "## Instanciação\n",
        "##\n",
        "sharepoint = Sharepoint.instance()\n",
        "sharepoint.load()\n",
        "sharepoint.show_pastas()\n",
        "sharepoint.show_votos()\n",
        "sharepoint.show_resumo()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFpyD1qoI5Qn"
      },
      "source": [
        "#@title **GERAR ARQUIVO `JSON`**\n",
        "\n",
        "sharepoint.download()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXliWd1Bs_fR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}